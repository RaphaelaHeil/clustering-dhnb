{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3676ff-e127-45f8-9f28-fe27156f3471",
   "metadata": {},
   "source": [
    "# Clustering-based Analysis of Handwritten Digits\n",
    "\n",
    "This notebook is part of the DHNB 2022 tutorial \"Introduction to Text and Image Analysis Using Python\" (website: [https://raphaelaheil.github.io/2022-03-15-dhnb/](https://raphaelaheil.github.io/2022-03-15-dhnb/)). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a01d310-00bd-40f2-990e-483e337c2d21",
   "metadata": {},
   "source": [
    "## Session Objectives\n",
    "\n",
    "- demonstrate a general image processing pipeline\n",
    "- provide an example of how clustering can be used to annotate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a69ac3-ed76-4a3d-a462-9f46314c59db",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "This notebook uses the following dataset:\n",
    "> \"DIDA is a new image-based historical handwritten digit dataset and collected from the Swedish historical handwritten document images between the year 1800 and 1940\"\n",
    ">\n",
    "> from [https://didadataset.github.io/DIDA/](https://didadataset.github.io/DIDA/)\n",
    "\n",
    ">A Deep Handwritten Digit Detection and Recognition Method Using a New Historical Handwritten Digit Dataset, Huseyin Kusetogullari, Amir Yavariabdi, Johan Hall, Niklas Lavesson,\n",
    "DIGITNET: \n",
    "Big Data Research,\n",
    "Volume 23,\n",
    "2021,\n",
    "100182,\n",
    "ISSN 2214-5796,\n",
    "https://doi.org/10.1016/j.bdr.2020.100182.\n",
    "(https://www.sciencedirect.com/science/article/pii/S2214579620300502)\n",
    "\n",
    "Original dataset download: [https://didadataset.github.io/DIDA/](https://didadataset.github.io/DIDA/)\n",
    "\n",
    "Workshop dataset download: [https://github.com/RaphaelaHeil/clustering-dhnb/releases/download/v1.0/digits.zip](https://github.com/RaphaelaHeil/clustering-dhnb/releases/download/v1.0/digits.zip)\n",
    "\n",
    "_For usability reasons, the original dataset has been restructured and compressed as a *.zip, instead of *.rar for the purpose of the workshop. The images themselves however remain unchanged._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e92584-70e0-44ac-b2e3-d0f9dd3e9cb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## General Pipeline\n",
    "\n",
    "1. Load images\n",
    "2. Preprocess\n",
    "    1. resize images to fixed dimensions (64x64px)\n",
    "    2. turn colour (RGB) images into greyscale\n",
    "    3. turn greyscale images into black and white (\"[Otsu's Method](https://en.wikipedia.org/wiki/Otsu%27s_method)\")\n",
    "4. Extract features (\"[Histogram of Oriented Gradients](https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients)\")\n",
    "5. Cluster features (\"[k-Means](https://en.wikipedia.org/wiki/K-means_clustering)\") \n",
    "\n",
    "![Visualisation of intermediate results of the processing pipeline](pipeline.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b604107-40e1-4254-8c6b-900194714e3f",
   "metadata": {},
   "source": [
    "Clustering-based Analysis of Handwritten Characters--- \n",
    "\n",
    "## Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21791602-383f-4e66-ae08-1c68e95c9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46381ecb-dab4-4a5d-8475-3a3ddd54db47",
   "metadata": {},
   "source": [
    "### Brief introduction of the main packages:\n",
    "\n",
    "**Matplotlib**\n",
    "> Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
    ">\n",
    "> from [https://matplotlib.org/](https://matplotlib.org/)\n",
    "\n",
    "Documentation: [https://matplotlib.org/stable/api/index](https://matplotlib.org/stable/api/index)\n",
    "\n",
    "Extensive gallery of examples: [https://matplotlib.org/stable/gallery/index.html](https://matplotlib.org/stable/gallery/index.html)\n",
    "\n",
    "**Numpy**\n",
    "> \"NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\" \n",
    ">\n",
    "> from [https://numpy.org/](https://numpy.org/)\n",
    "\n",
    "Documentation: [https://numpy.org/doc/stable/reference/index.html#reference](https://numpy.org/doc/stable/reference/index.html#reference)\n",
    "\n",
    "**Skimage (scikit-image)**\n",
    "> \"scikit-image is a collection of algorithms for image processing.\"\n",
    ">\n",
    "> from [https://scikit-image.org/](https://scikit-image.org/)\n",
    "\n",
    "Documentation: [https://scikit-image.org/docs/stable/api/api.html](https://scikit-image.org/docs/stable/api/api.html)\n",
    "\n",
    "Gallery of examples: [https://scikit-image.org/docs/stable/auto_examples/index.html](https://scikit-image.org/docs/stable/auto_examples/index.html)\n",
    "\n",
    "**Sklearn (scikit-learn)**\n",
    "> \"Simple and efficient tools for predictive data analysis.\"\n",
    "> \n",
    "> from [https://scikit-learn.org/](https://scikit-learn.org/)\n",
    "\n",
    "Documentation: [https://scikit-learn.org/stable/modules/classes.html](https://scikit-learn.org/stable/modules/classes.html)\n",
    "\n",
    "User guide: [https://scikit-learn.org/stable/user_guide.html](https://scikit-learn.org/stable/user_guide.html)\n",
    "\n",
    "**utils**\n",
    "\n",
    "A utility package, made specially for this tutorial. It contains helper methods for loading, processing and visualising the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca2585-47b6-4755-8060-3c42d2307be7",
   "metadata": {},
   "source": [
    "## 1 Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53628a6-757f-478e-be5a-4292795e2362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b856b11d-f484-46a4-a04f-e180bd167b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4c2076-a3d9-408f-8a7b-3c34736a7a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4aa104-4412-46cc-bc15-e300328dc1ef",
   "metadata": {},
   "source": [
    "## 2 Pre-processing\n",
    "\n",
    "1. resize images to fixed dimensions (64x64px)\n",
    "2. turn colour (RGB) images into greyscale\n",
    "3. turn greyscale images into black and white (\"[Otsu's Method](https://en.wikipedia.org/wiki/Otsu%27s_method)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1dcaf-51ae-4dee-9d90-ded7a5da58ba",
   "metadata": {},
   "source": [
    "### 2.1 Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf43dc7c-a003-402f-b732-a118f8f0bde7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e091532-d388-4172-a1f3-c4d7f0a72eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "857ac797-4d40-4102-ad64-031e21f77b23",
   "metadata": {},
   "source": [
    "### 2.2 Greyscale Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6440933-1f22-459a-b89c-59eecbbbc065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e42d7-5824-475e-9ea0-19eb5a9806f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6945519a-8cbc-4474-a1d0-afc43123d1a3",
   "metadata": {},
   "source": [
    "### 2.3 Conversion to Black and White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c07eb-7c3c-49e0-bbbf-7590876027e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916bf5d-ee06-4a25-85c9-32bce595f7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e62d47-6cad-47ef-9651-d20784c8ff93",
   "metadata": {},
   "source": [
    "## 3 Feature Extraction: Histogram of Oriented Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef017492-1a22-46b3-8e59-64b513cfb442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0df29-a055-4a71-85ec-2da91e7c6247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18cfb101-7d80-46ac-a786-61798218f908",
   "metadata": {},
   "source": [
    "## 4 Clustering: k-Means Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b661cc0e-fdad-4a74-93a5-6791230dd32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0011549-e783-448b-9018-bc94d03f2934",
   "metadata": {},
   "source": [
    "## 5 Bulk Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f0ca00-d3b3-40ec-bd55-e9c0a58a87a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9263dff6-5038-432b-a8c1-cf5e1ddaea3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a4b30a-6f7a-40e3-b6da-1d5ee9e9c0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33972014-d7ca-4651-acc1-e9811ffe8ed0",
   "metadata": {},
   "source": [
    "## 6 Ground Truth Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb6935b-b987-4c19-8763-62afee759843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e4cdf-109a-451b-a0c7-7a57f13510b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhnb22",
   "language": "python",
   "name": "dhnb22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
